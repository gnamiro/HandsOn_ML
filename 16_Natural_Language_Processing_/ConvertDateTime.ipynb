{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will try to train an Encoder-Decoder model that can convert a date string from one format to another"
      ],
      "metadata": {
        "id": "lUJaRAwyLP9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xLJ908x1JZWS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ],
      "metadata": {
        "id": "2t6U7oHHK7ER"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"nlp\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "TFJKRGmHK82S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by creating the dataset. We will use random days between 1000-01-01 and 9999-12-31:"
      ],
      "metadata": {
        "id": "OF70qQEJf5d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "MONTHS = ['January', 'Feburary', 'March', 'April', 'May', 'June', 'July',\n",
        "          'August', 'September', 'October', 'November', 'December']\n",
        "\n",
        "def random_dates(n_dates):\n",
        "  min_date = date(1000, 1, 1).toordinal()\n",
        "  max_date = date(9999, 12, 31).toordinal()\n",
        "\n",
        "  ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "  dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "\n",
        "  x = [MONTHS[dt.month - 1] + ' ' + dt.strftime('%d, %Y') for dt in dates]\n",
        "  y = [dt.isoformat() for dt in dates]\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "28uG8Tbsf5up"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "n_dates = 3\n",
        "x_example, y_example = random_dates(n_dates)\n",
        "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
        "print(\"-\" * 50)\n",
        "for idx in range(n_dates):\n",
        "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLIJfD7whUsk",
        "outputId": "76bf742b-4894-4259-cfba-0852566f8a96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input                    Target                   \n",
            "--------------------------------------------------\n",
            "September 20, 7075       7075-09-20               \n",
            "May 15, 8579             8579-05-15               \n",
            "January 11, 7103         7103-01-11               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the list of all possible characters in the inputs:"
      ],
      "metadata": {
        "id": "QjvOKYpDc9sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHARS = ''.join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
        "INPUT_CHARS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AYGvRi4KhYkU",
        "outputId": "0e9400e8-661c-4ee9-b60d-cfe238e1f7fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here's the list of possible characters in the outputs:"
      ],
      "metadata": {
        "id": "y2WX2z2FdNxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_CHARS = \"0123456789-\""
      ],
      "metadata": {
        "id": "n47aygD1dJyp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a function to convert a string to a list of character IDs, as we did in the previous exercise:"
      ],
      "metadata": {
        "id": "JasRkuvgdQHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
        "    return [chars.index(c) for c in date_str]"
      ],
      "metadata": {
        "id": "Rhs2xp4OdOD2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_str_to_ids(x_example[0], INPUT_CHARS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJH9nOOndUaR",
        "outputId": "f04f6a67-6bcd-422e-bad3-dc7a075558a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuvZFIGPdWi2",
        "outputId": "e4dc6eb4-3141-4d68-8e41-89524f965905"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
        "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
        "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
        "    return (X + 1).to_tensor() # using 0 as the padding token ID\n",
        "\n",
        "def create_dataset(n_dates):\n",
        "    x, y = random_dates(n_dates)\n",
        "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
      ],
      "metadata": {
        "id": "lk3PoOtYdX1m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "X_train, Y_train = create_dataset(10000)\n",
        "X_valid, Y_valid = create_dataset(2000)\n",
        "X_test, Y_test = create_dataset(2000)"
      ],
      "metadata": {
        "id": "15RTqN1ldkA9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9wHaXRKdlgw",
        "outputId": "f14a0342-154a-4a67-c81e-077077d5cb96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First version: a very basic seq2seq model\n",
        "\n",
        "Let's first try the simplest possible model: we feed in the input sequence, which first goes through the encoder (an embedding layer followed by a single LSTM layer), which outputs a vector, then it goes through a decoder (a single LSTM layer, followed by a dense output layer), which outputs a sequence of vectors, each representing the estimated probabilities for all possible output character.\n",
        "\n",
        "Since the decoder expects a sequence as input, we repeat the vector (which is output by the encoder) as many times as the longest possible output sequence."
      ],
      "metadata": {
        "id": "kGxwzUl4dou8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "max_output_length = Y_train.shape[1]\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
        "                              output_dim=embedding_size,\n",
        "                              input_shape=[None]),\n",
        "    tf.keras.layers.LSTM(128)\n",
        "])\n",
        "\n",
        "decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    encoder, \n",
        "    tf.keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-bCzDGqdmcm",
        "outputId": "9f187482-7a62-424d-d4c0-ba41300d5856"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 14s 13ms/step - loss: 1.7338 - accuracy: 0.3729 - val_loss: 1.3065 - val_accuracy: 0.5235\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3145 - accuracy: 0.5280 - val_loss: 1.0674 - val_accuracy: 0.6206\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.9063 - accuracy: 0.6736 - val_loss: 0.7695 - val_accuracy: 0.7201\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6446 - accuracy: 0.7568 - val_loss: 0.5403 - val_accuracy: 0.7962\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8130 - accuracy: 0.7116 - val_loss: 0.5214 - val_accuracy: 0.8010\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4094 - accuracy: 0.8425 - val_loss: 0.3390 - val_accuracy: 0.8726\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2698 - accuracy: 0.9034 - val_loss: 0.2218 - val_accuracy: 0.9275\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1630 - accuracy: 0.9550 - val_loss: 0.1182 - val_accuracy: 0.9699\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3950 - accuracy: 0.8897 - val_loss: 0.1812 - val_accuracy: 0.9583\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1148 - accuracy: 0.9787 - val_loss: 0.0836 - val_accuracy: 0.9855\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0583 - accuracy: 0.9919 - val_loss: 0.0464 - val_accuracy: 0.9932\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0343 - accuracy: 0.9964 - val_loss: 0.0287 - val_accuracy: 0.9970\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0217 - accuracy: 0.9984 - val_loss: 0.0196 - val_accuracy: 0.9980\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0141 - accuracy: 0.9995 - val_loss: 0.0130 - val_accuracy: 0.9992\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0095 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 0.9992\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0065 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 0.9996\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9998\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9998\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
        "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
        "            for sequence in ids]"
      ],
      "metadata": {
        "id": "Dk_30CS1OViv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = prepare_date_strs([\"September 17, 2009\", \"July 14, 1789\"])"
      ],
      "metadata": {
        "id": "KimbxaZvOzab"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = model.predict(X_new).argmax(axis=-1)\n",
        "for date_str in ids_to_date_strs(ids):\n",
        "    print(date_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjZHYDzZO05b",
        "outputId": "021b1c00-5d5f-4319-8ecf-0f3f0ecfcd58"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "2009-09-17\n",
            "1789-07-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the model was only trained on input strings of length 18 (which is the length of the longest date), it does not perform well if we try to use it to make predictions on shorter sequences:"
      ],
      "metadata": {
        "id": "cNU89MdUO6oX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
      ],
      "metadata": {
        "id": "IGgcpU1JO11j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = model.predict(X_new).argmax(axis=-1)\n",
        "for date_str in ids_to_date_strs(ids):\n",
        "    print(date_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lgvlWP9O_Iz",
        "outputId": "3a67f167-df56-43de-f8f3-113374287fec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 943ms/step\n",
            "2020-01-02\n",
            "1789-09-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oops! We need to ensure that we always pass sequences of the same length as during training, using padding if necessary. Let's write a little helper function for that:"
      ],
      "metadata": {
        "id": "NKTk5-RBPFMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = X_train.shape[1]\n",
        "\n",
        "def prepare_date_strs_padded(date_strs):\n",
        "    X = prepare_date_strs(date_strs)\n",
        "    if X.shape[1] < max_input_length:\n",
        "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
        "    return X\n",
        "\n",
        "def convert_date_strs(date_strs):\n",
        "    X = prepare_date_strs_padded(date_strs)\n",
        "    ids = model.predict(X).argmax(axis=-1)\n",
        "    return ids_to_date_strs(ids)"
      ],
      "metadata": {
        "id": "hoszuupqO_X-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLFCJ66YPLyF",
        "outputId": "c86a5e2d-c0c2-4df0-8c15-d4a8a806a057"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2020-05-02', '1789-07-14']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's build a more powerful model."
      ],
      "metadata": {
        "id": "k3iADhfkPUF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second version: feeding the shifted targets to the decoder (teacher forcing)\n",
        "\n",
        "Instead of feeding the decoder a simple repetition of the encoder's output vector, we can feed it the target sequence, shifted by one time step to the right. This way, at each time step the decoder will know what the previous target character was. This should help is tackle more complex sequence-to-sequence problems.\n",
        "\n",
        "Since the first output character of each target sequence has no previous character, we will need a new token to represent the start-of-sequence (sos).\n",
        "\n",
        "During inference, we won't know the target, so what will we feed the decoder? We can just predict one character at a time, starting with an sos token, then feeding the decoder all the characters that were predicted so far.\n",
        "\n",
        "But if the decoder's LSTM expects to get the previous target as input at each step, how shall we pass it it the vector output by the encoder? Well, one option is to ignore the output vector, and instead use the encoder's LSTM state as the initial state of the decoder's LSTM (which requires that encoder's LSTM must have the same number of units as the decoder's LSTM).\n",
        "\n",
        "Now let's create the decoder's inputs (for training, validation and testing). The sos token will be represented using the last possible output character's ID + 1."
      ],
      "metadata": {
        "id": "VsJCA3ZnPWJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = len(OUTPUT_CHARS) + 1\n",
        "\n",
        "def shifted_output_sequences(Y):\n",
        "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
        "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
        "\n",
        "X_train_decoder = shifted_output_sequences(Y_train)\n",
        "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
        "X_test_decoder = shifted_output_sequences(Y_test)"
      ],
      "metadata": {
        "id": "xSIv1q_KPsad"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzmttG1zPsXQ",
        "outputId": "aa407b31-e3d4-426c-98b3-8574f86e2735"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10000, 10), dtype=int32, numpy=\n",
              "array([[12,  8,  1, ..., 10, 11,  3],\n",
              "       [12,  9,  6, ...,  6, 11,  2],\n",
              "       [12,  8,  2, ...,  2, 11,  2],\n",
              "       ...,\n",
              "       [12, 10,  8, ...,  2, 11,  4],\n",
              "       [12,  2,  2, ...,  3, 11,  3],\n",
              "       [12,  8,  9, ...,  8, 11,  3]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's build the model. It's not a simple sequential model anymore, so let's use the functional API:"
      ],
      "metadata": {
        "id": "8wYKjrBAQB_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "lstm_units = 128\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder_input = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "encoder_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim = len(INPUT_CHARS) + 1,\n",
        "    output_dim = encoder_embedding_size)(encoder_input)\n",
        "_, encoder_state_h, encoder_state_c = tf.keras.layers.LSTM(\n",
        "    lstm_units, return_state=True)(encoder_embedding)\n",
        "\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim=len(OUTPUT_CHARS)+2,\n",
        "    output_dim=decoder_embedding_size)(decoder_input)\n",
        "\n",
        "decoder_lstm_output = tf.keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
        "    decoder_embedding, initial_state=encoder_state)\n",
        "decoder_output = tf.keras.layers.Dense(len(OUTPUT_CHARS)+1,\n",
        "                                       activation='softmax')(decoder_lstm_output)\n",
        "\n",
        "model = tf.keras.Model(inputs=[encoder_input, decoder_input],\n",
        "                       outputs=[decoder_output])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10,\n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjh-5WK6PM4f",
        "outputId": "e343d40f-a049-46b3-b391-f0dd70169d9a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 9s 15ms/step - loss: 1.6135 - accuracy: 0.3970 - val_loss: 1.4010 - val_accuracy: 0.4436\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0746 - accuracy: 0.6072 - val_loss: 0.8071 - val_accuracy: 0.7268\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5831 - accuracy: 0.8059 - val_loss: 0.4127 - val_accuracy: 0.8720\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2367 - accuracy: 0.9430 - val_loss: 0.1364 - val_accuracy: 0.9796\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0863 - accuracy: 0.9912 - val_loss: 0.0583 - val_accuracy: 0.9965\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0382 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9987\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1340 - accuracy: 0.9755 - val_loss: 0.0294 - val_accuracy: 0.9995\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0206 - accuracy: 0.9997 - val_loss: 0.0158 - val_accuracy: 0.9999\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9999\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model also reaches 100% validation accuracy, but it does so even faster.\n",
        "\n",
        "Let's once again use the model to make some predictions. This time we need to predict characters one by one."
      ],
      "metadata": {
        "id": "dkLNNTDKR6Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = len(OUTPUT_CHARS) + 1\n",
        "\n",
        "def predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_padded(date_strs)\n",
        "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
        "    for index in range(max_output_length):\n",
        "        pad_size = max_output_length - Y_pred.shape[1]\n",
        "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
        "        Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
        "        Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
        "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=1)\n",
        "    return ids_to_date_strs(Y_pred[:, 1:])"
      ],
      "metadata": {
        "id": "6bcgi_gXRrFs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YxEnRNCR8sx",
        "outputId": "ae2aa608-62a1-440e-9c28-e360ce648d6f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 616ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1789-07-14', '2020-05-01']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-zV-M7SR9tz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}